{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining functions for download, unpacking processing and saving the fire data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for instalation of cdsapi follow https://cds.climate.copernicus.eu/api-how-to"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this function wil downlaod both pixel and grid data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "\n",
    "def data_download(year, month, region):\n",
    "\n",
    "    c = cdsapi.Client()\n",
    "    c.retrieve(\n",
    "        'satellite-fire-burned-area',\n",
    "        {\n",
    "            'origin': 'esa_cci',\n",
    "            'sensor': 'modis',\n",
    "            'variable': 'pixel_variables',\n",
    "            'version': '5_1_1cds',\n",
    "            'region': f'{region}',\n",
    "            'year': f'{year}',\n",
    "            'month': f'{str(month).zfill(2)}',\n",
    "            'nominal_day': '01',\n",
    "            'format': 'tgz',\n",
    "        },\n",
    "        f'../data/{region}_{year}_{str(month).zfill(2)}_pixel.tar.gz')\n",
    "    \n",
    "    c = cdsapi.Client()\n",
    "\n",
    "    c.retrieve(\n",
    "        'satellite-fire-burned-area',\n",
    "        {\n",
    "            'origin': 'esa_cci',\n",
    "            'sensor': 'modis',\n",
    "            'variable': 'grid_variables',\n",
    "            'version': '5_1_1cds',\n",
    "            'region': f'{region}',\n",
    "            'year': f'{year}',\n",
    "            'month': f'{str(month).zfill(2)}',\n",
    "            'nominal_day': '01',\n",
    "            'format': 'tgz',\n",
    "        },\n",
    "        f'../data/{region}_{year}_{str(month).zfill(2)}_grid.tar.gz')\n",
    "       \n",
    "    return unpack_data()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this function unpacks data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def unpack_data():\n",
    "    import os\n",
    "    import glob\n",
    "    data_dir = '../data'\n",
    "\n",
    "# Find all .tar.gz files in the data directory\n",
    "    tar_files = glob.glob(os.path.join(data_dir, '*.tar.gz'))\n",
    "\n",
    "# Unpack and remove each .tar.gz file\n",
    "    for tar_file in tar_files:\n",
    "        os.system(f'tar -xf {tar_file} -C {data_dir}')\n",
    "        os.remove(tar_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data and saving the output as fire.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is used to round lat and lon to shrink the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def round_to_nearest_025(x):\n",
    "    return np.round(x * 4) / 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### this is for preprocessing fire pixel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "def pixel_preprocessing(file_path):\n",
    "    pixel_ds = xr.open_dataset(file_path, engine='netcdf4')\n",
    "\n",
    "    pixel_ds['lat'] = xr.apply_ufunc(round_to_nearest_025, pixel_ds['lat'])\n",
    "    pixel_ds['lon'] = xr.apply_ufunc(round_to_nearest_025, pixel_ds['lon'])\n",
    "\n",
    "    filtered_data = pixel_ds.squeeze('time')\n",
    "    filtered_data = filtered_data.sel(lat=slice(52, 33), lon=slice(-10, 50))\n",
    "    filtered_data = filtered_data[['CL',\n",
    "                                   'lat_bounds',\n",
    "                                   'lon_bounds'\n",
    "                                   ]]\n",
    "\n",
    "    filtered_data = filtered_data.drop_duplicates(dim=['lat','lon'])\n",
    "\n",
    "    pixel_df = filtered_data.to_dataframe().reset_index()\n",
    "    pixel_df = pixel_df.drop(['lat_bounds', 'lon_bounds', 'bounds'], axis = 1)\n",
    "\n",
    "    #pixel_df['year'] = pixel_df['time'].dt.year\n",
    "    #pixel_df['month'] = pixel_df['time'].dt.month\n",
    "    #pixel_df = pixel_df.drop('time', axis= 1).dropna()\n",
    "    return pixel_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### this is for preprocessing fire grid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fire_preprocessing(file_path):\n",
    "    ds_fire = xr.open_dataset(file_path, engine='netcdf4')\n",
    "    \n",
    "    filtered_data = ds_fire.squeeze('time')\n",
    "    filtered_data = filtered_data.sel(lat=slice(52, 33), lon=slice(-10, 50))\n",
    "    filtered_data = filtered_data[['burned_area',\n",
    "                                   'fraction_of_burnable_area',\n",
    "                                   'lat_bounds',\n",
    "                                   'lon_bounds'\n",
    "                                   ]]\n",
    "    filtered_data = filtered_data.where(filtered_data['fraction_of_burnable_area'] > 0, drop = True)\n",
    "#    filtered_data = filtered_data.where(filtered_data['burned_area'] > 1, drop = True)\n",
    "\n",
    "    fire_df = filtered_data.to_dataframe().reset_index()\n",
    "    #fire_df['year'] = fire_df['time'].dt.year\n",
    "    #fire_df['month'] = fire_df['time'].dt.month\n",
    "    fire_df = fire_df.drop(['lat', 'lon', 'bounds'], axis= 1).drop_duplicates().dropna()\n",
    "    \n",
    "    return fire_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with this function you can preprocess bot grid and pixel data at the same time and combine them into single output in fire.csv folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here you can use the functions to download the data and unpack it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_download' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/tomasd/code/TomasDemeter/FireProject/notebooks/tomas_preprocessing.ipynb Cell 17\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tomasd/code/TomasDemeter/FireProject/notebooks/tomas_preprocessing.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_year, end_year \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tomasd/code/TomasDemeter/FireProject/notebooks/tomas_preprocessing.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_month, end_month \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/tomasd/code/TomasDemeter/FireProject/notebooks/tomas_preprocessing.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m         data_download(i, j, region)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_download' is not defined"
     ]
    }
   ],
   "source": [
    "#just select date and region\n",
    "#modifying forloop should not be necessary\n",
    "\n",
    "start_year = 2001\n",
    "end_year = 2019\n",
    "start_month = 9\n",
    "end_month = 12\n",
    "region = 'europe'\n",
    "\n",
    "for i in range(start_year, end_year + 1):\n",
    "    for j in range(start_month, end_month + 1):\n",
    "        data_download(i, j, region)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this will call the preprocessing functions on all the .nc files in ../data folder, preprocess it and save the result in ../data folder in fire.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fire_gird_and_pixel(data_dir):\n",
    "    \n",
    "    first_iteration = True\n",
    "    column_order = ['lat_bounds',\n",
    "                        'lon_bounds',\n",
    "                        'fraction_of_burnable_area',\n",
    "                        'burned_area',\n",
    "                        'CL',\n",
    "                        'time'\n",
    "                        ]\n",
    "    \n",
    "    #create dict of file pairs to make sure crrect files are procesed together\n",
    "    file_pairs = {}\n",
    "\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        if file_name.endswith('.nc') and 'FIRE' in file_name:\n",
    "            file_prefix = file_name[:8]\n",
    "\n",
    "            if file_prefix in file_pairs:\n",
    "                file_pairs[file_prefix].append(file_name)\n",
    "            else:\n",
    "                file_pairs[file_prefix] = [file_name]\n",
    "    \n",
    "    # the two files grid and pixel are processed here\n",
    "    for file_prefix, file_pair in file_pairs.items():\n",
    "        if len(file_pair) == 2:\n",
    "            for file_name in file_pair:\n",
    "                file_path = os.path.join(data_dir, file_name)\n",
    "                if 'AREA' in file_name:\n",
    "                    df_pixel = pixel_preprocessing(file_path)\n",
    "                else:\n",
    "                    df_grid = fire_preprocessing(file_path)\n",
    "    \n",
    "            merged_df = df_pixel.merge(\n",
    "                        df_grid,\n",
    "                        left_on=['lat', 'lon', 'time'],\n",
    "                        right_on=['lat_bounds', 'lon_bounds', 'time']) # merges pixel and grid data\n",
    "            \n",
    "            merged_df = merged_df.drop(['lat', 'lon'], axis = 1).drop_duplicates() # drops unnecesary columns\n",
    "            merged_df = merged_df[column_order] # reorder columns\n",
    "            \n",
    "            if first_iteration:\n",
    "                merged_df.to_csv(os.path.join(data_dir, 'fire3.csv'), index=False)\n",
    "                first_iteration = False\n",
    "            else:\n",
    "                merged_df.to_csv(os.path.join(data_dir, 'fire3.csv'), mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_gird_and_pixel('../data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
